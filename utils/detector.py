"""
utils/detector.py - YOLOv8 Pallet Detector
à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¹€à¸¥à¸—à¸”à¹‰à¸§à¸¢ YOLOv8
"""

import cv2
import os
from ultralytics import YOLO
from datetime import datetime
import config
from utils.logger import setup_logger
from shapely.geometry import Polygon, box as shapely_box

logger = setup_logger()

class PalletDetector:  
    """Class à¸ªà¸³à¸«à¸£à¸±à¸š detect à¸à¸²à¹€à¸¥à¸—à¸”à¹‰à¸§à¸¢ YOLO"""
    
    def __init__(self):
        """Initialize detector"""
        self.cfg = config.load_config()
        self.model_path = self. cfg['detection']['modelPath']
        self.confidence = self.cfg['detection']['confidenceThreshold']
        self.iou = self.cfg['detection']['iouThreshold']
        self.img_size = self.cfg['detection']['imageSize']
        self.device = self.cfg['detection']['deviceMode']
        
        # à¹‚à¸«à¸¥à¸” YOLO model
        try:
            self.model = YOLO(self.model_path)
            logger.info(f"âœ… YOLOv8 model loaded:   {self.model_path}")
            
            # âœ… à¹à¸ªà¸”à¸‡ class names
            logger.info(f"ğŸ“‹ Model classes: {self. model.names}")
            
        except Exception as e:
            logger.error(f"âŒ Cannot load YOLO model: {e}")
            raise
    
    def detect_pallets(self, image_path):
        """
        à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸à¸²à¹€à¸¥à¸—à¹à¸¥à¸°à¸„à¸™à¹ƒà¸™à¸£à¸¹à¸› (Multi-class detection)
        
        Args: 
            image_path (str): path à¸‚à¸­à¸‡à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸ˆà¸° detect
            
        Returns:  
            dict:  {
                'count': int,
                'pallets': [
                    {
                        'bbox': [x1, y1, x2, y2],
                        'center': [cx, cy],
                        'confidence': float,
                        'class_name': str,
                        'class_type': str  # 'pallet' or 'person'
                    }
                ],
                'image_path':  str,
                'original_image': numpy.ndarray
            }
        """
        try:
            # à¸­à¹ˆà¸²à¸™à¸£à¸¹à¸›
            image = cv2.imread(image_path)
            if image is None:
                logger.error(f"Cannot read image: {image_path}")
                return None
            
            # Run detection (à¹„à¸¡à¹ˆà¸à¸£à¸­à¸‡ class à¹ƒà¸«à¹‰ detect à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡)
            results = self.model.predict(
                source=image,
                conf=self.confidence,
                iou=self.iou,
                imgsz=self.img_size,
                device=self.device,
                classes=None,  # âœ… à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¸—à¸¸à¸ class
                verbose=False
            )
            
            # âœ… à¸”à¸¶à¸‡ class names
            class_names = self.model.names
            
            # Parse results
            pallets = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    # à¸”à¸¶à¸‡ class ID
                    class_id = int(box.cls[0])
                    class_name = class_names[class_id]
                    
                    # âœ… à¸à¸£à¸­à¸‡à¹€à¸‰à¸à¸²à¸° pallet à¹à¸¥à¸° person (case-insensitive)
                    class_name_lower = class_name.lower()
                    if 'pallet' in class_name_lower:
                        class_type = 'pallet'
                    elif 'person' in class_name_lower:
                        class_type = 'person'
                    else:
                        logger.debug(f"Filtered out: {class_name}")
                        continue
                    
                    # Bounding box coordinates
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # Center point
                    cx = (x1 + x2) / 2
                    cy = (y1 + y2) / 2
                    
                    # Confidence
                    conf = float(box.conf[0])
                    
                    pallets.append({
                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                        'center': [float(cx), float(cy)],
                        'confidence': conf,
                        'class_name': class_name,
                        'class_type': class_type  # âœ… à¹€à¸à¸´à¹ˆà¸¡ class_type
                    })
            
            logger.info(f"Detected {len(pallets)} object(s) in {os.path.basename(image_path)}")
            
            return {
                'count':   len(pallets),
                'pallets': pallets,
                'image_path': image_path,
                'original_image': image  # âœ… à¸„à¸·à¸™à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¹à¸—à¸™ annotated
            }
            
        except Exception as e:
            logger.error(f"Detection error: {e}")
            return None
    
    def save_annotated_image(self, original_image, pallets, original_path, db_manager):
        """
        à¸§à¸²à¸”à¸à¸£à¸­à¸šà¹à¸¥à¸° label à¹à¸šà¸šà¸à¸³à¸«à¸™à¸”à¹€à¸­à¸‡ à¸à¸£à¹‰à¸­à¸¡à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š
        
        Args:
            original_image: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š
            pallets: list à¸‚à¸­à¸‡ detection results (à¸ˆà¸°à¸–à¸¹à¸ modified in-place)
            original_path:  path à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š
            db_manager: DatabaseManager instance à¸ªà¸³à¸«à¸£à¸±à¸š query pallet_no
            
        Returns:
            str: path à¸‚à¸­à¸‡à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸šà¸±à¸™à¸—à¸¶à¸
        """
        try:
            # à¸„à¸±à¸”à¸¥à¸­à¸à¸£à¸¹à¸›à¹€à¸à¸·à¹ˆà¸­à¸§à¸²à¸”à¸à¸£à¸­à¸š
            annotated = original_image.copy()
            
            # âœ… à¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š: top-to-bottom (y), left-to-right (x)
            sorted_pallets = sorted(pallets, key=lambda p: (p['center'][1], p['center'][0]))
            
            # âœ… Query à¹€à¸¥à¸‚ pallet_no à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
            latest_no = db_manager.get_latest_pallet_no()
            next_no = latest_no + 1
            
            # âœ… Prefix à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸° class
            PALLET_PREFIX = "PL-"
            PERSON_PREFIX = "PE-"
            
            # âœ… à¸à¸³à¸«à¸™à¸”à¸ªà¸µ (BGR format)
            COLOR_PALLET = (0, 255, 0)   # à¹€à¸‚à¸µà¸¢à¸§
            COLOR_PERSON = (255, 0, 0)   # à¸™à¹‰à¸³à¹€à¸‡à¸´à¸™
            
            # à¸§à¸²à¸”à¸à¸£à¸­à¸šà¹à¸¥à¸° label
            for pallet in sorted_pallets:
                class_type = pallet['class_type']
                bbox = pallet['bbox']
                confidence = pallet['confidence']
                
                # à¸à¸³à¸«à¸™à¸” prefix à¹à¸¥à¸°à¸ªà¸µ
                if class_type == 'pallet':
                    prefix = PALLET_PREFIX
                    color = COLOR_PALLET
                elif class_type == 'person':
                    prefix = PERSON_PREFIX
                    color = COLOR_PERSON
                else:
                    continue
                
                # âœ… à¹ƒà¸Šà¹‰à¹€à¸¥à¸‚à¹€à¸à¹ˆà¸²à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸à¸²à¹€à¸¥à¸—à¹€à¸”à¸´à¸¡, à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸«à¸¡à¹ˆà¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸à¸²à¹€à¸¥à¸—à¹ƒà¸«à¸¡à¹ˆ
                if pallet.get('is_existing', False):
                    # à¹ƒà¸Šà¹‰à¹€à¸¥à¸‚à¹€à¸à¹ˆà¸²
                    pallet_no = pallet.get('pallet_no', next_no)
                    pallet_name = pallet.get('pallet_name', f"{prefix}{next_no:04d}")
                else:
                    # à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸¥à¸‚à¹ƒà¸«à¸¡à¹ˆ
                    pallet_name = f"{prefix}{next_no:04d}"
                    pallet['pallet_no'] = next_no
                    pallet['pallet_name'] = pallet_name
                    next_no += 1
                    
                    # âœ… à¸­à¸±à¸›à¹€à¸”à¸•à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸¥à¸±à¸šà¹„à¸›à¸—à¸µà¹ˆ pallets à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š (à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸šà¸±à¸™à¸—à¸¶à¸à¸¥à¸‡ database à¹„à¸”à¹‰)
                    for orig_pallet in pallets:
                        # à¸«à¸²à¸•à¸±à¸§à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹‚à¸”à¸¢à¹€à¸—à¸µà¸¢à¸š center à¹à¸¥à¸° bbox
                        if (orig_pallet.get('center') == pallet['center'] and 
                            orig_pallet.get('bbox') == pallet['bbox']):
                            orig_pallet['pallet_no'] = pallet['pallet_no']
                            orig_pallet['pallet_name'] = pallet['pallet_name']
                            logger.debug(f"âœ… Updated original pallet: {pallet['pallet_name']}")
                            break
                
                # à¸§à¸²à¸”à¸à¸£à¸­à¸š
                x1, y1, x2, y2 = bbox
                cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
                
                # à¸ªà¸£à¹‰à¸²à¸‡ label text
                label = f"{pallet_name} ({confidence*100:.1f}%)"
                
                # à¸„à¸³à¸™à¸§à¸“à¸‚à¸™à¸²à¸” text
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.6
                thickness = 2
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, font, font_scale, thickness
                )
                
                # à¸§à¸²à¸”à¸à¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡ label
                cv2.rectangle(
                    annotated,
                    (x1, y1 - text_height - baseline - 10),
                    (x1 + text_width + 10, y1),
                    color,
                    -1
                )
                
                # à¸§à¸²à¸” text
                cv2.putText(
                    annotated,
                    label,
                    (x1 + 5, y1 - baseline - 5),
                    font,
                    font_scale,
                    (255, 255, 255),  # à¸ªà¸µà¸‚à¸²à¸§
                    thickness
                )
            
            # à¸ªà¸£à¹‰à¸²à¸‡ path à¹ƒà¸«à¸¡à¹ˆ (à¹€à¸à¸´à¹ˆà¸¡ _detected)
            dir_name = os.path.dirname(original_path)
            file_name = os.path.basename(original_path)
            name, ext = os.path.splitext(file_name)
            new_path = os.path.join(dir_name, f"{name}_detected{ext}")
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸£à¸¹à¸›
            cv2.imwrite(new_path, annotated)
            logger.info(f"Saved annotated image:   {new_path}")
            
            return new_path
            
        except Exception as e: 
            logger.error(f"Cannot save annotated image: {e}")
            return None
    
    def calculate_bbox_overlap(self, bbox, zone_points, image_width, image_height):
        """
        à¸„à¸³à¸™à¸§à¸“ % à¸‚à¸­à¸‡ bbox à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ zone
        
        Args:
            bbox: [x1, y1, x2, y2] pixel coordinates
            zone_points: [[x1, y1], [x2, y2], ...] normalized (0.0-1.0)
            image_width, image_height: à¸‚à¸™à¸²à¸”à¸£à¸¹à¸›
            
        Returns:
            float: % overlap (0.0-1.0)
        """
        try:
            # à¹à¸›à¸¥à¸‡ bbox à¹€à¸›à¹‡à¸™ Polygon
            bbox_poly = shapely_box(bbox[0], bbox[1], bbox[2], bbox[3])
            
            # à¹à¸›à¸¥à¸‡ zone points (normalized 0.0-1.0) â†’ pixel
            pixel_points = [
                (p[0] * image_width, p[1] * image_height)
                for p in zone_points
            ]
            zone_poly = Polygon(pixel_points)
            
            # à¸„à¸³à¸™à¸§à¸“ intersection area
            if not bbox_poly.intersects(zone_poly):
                return 0.0
            
            intersection = bbox_poly.intersection(zone_poly)
            overlap_ratio = intersection.area / bbox_poly.area
            
            return overlap_ratio
            
        except Exception as e:
            logger.error(f"Error calculating overlap: {e}")
            return 0.0
    
    def filter_by_zones(self, detections, zones, image_width, image_height, threshold=0.5):
        """
        à¸à¸£à¸­à¸‡ detections à¹‚à¸”à¸¢à¹€à¸Šà¹‡à¸„à¸§à¹ˆà¸² bbox à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ zone > threshold %
        
        Args:
            detections: list of detection dicts
            zones: list of zone dicts with 'points' (normalized 0.0-1.0)
            image_width, image_height: à¸‚à¸™à¸²à¸”à¸£à¸¹à¸›
            threshold: % à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ zone (default 0.5 = 50%)
            
        Returns:
            list: filtered detections with 'zone_id', 'zone_name', 'zone_threshold'
        """
        if not zones:
            logger.debug("No zones configured, returning all detections")
            return detections
        
        filtered = []
        
        for detection in detections:
            bbox = detection['bbox']
            best_zone = None
            best_overlap = 0.0
            
            # à¸«à¸² zone à¸—à¸µà¹ˆ overlap à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”
            for zone in zones:
                if not zone.get('enabled', True):
                    continue
                
                overlap = self.calculate_bbox_overlap(
                    bbox, 
                    zone['points'], 
                    image_width, 
                    image_height
                )
                
                if overlap > best_overlap:
                    best_overlap = overlap
                    best_zone = zone
            
            # à¸–à¹‰à¸² overlap >= threshold â†’ à¹€à¸à¸´à¹ˆà¸¡à¹€à¸‚à¹‰à¸² filtered
            if best_zone and best_overlap >= threshold:
                detection['zone_id'] = best_zone['id']
                detection['zone_name'] = best_zone['name']
                detection['zone_threshold'] = best_zone.get('alertThreshold', 30)
                detection['overlap_ratio'] = round(best_overlap * 100, 1)
                filtered.append(detection)
                
                logger.debug(
                    f"Detection bbox={bbox} â†’ Zone '{best_zone['name']}' "
                    f"(overlap: {best_overlap*100:.1f}%)"
                )
            else:
                logger.debug(
                    f"Detection bbox={bbox} â†’ Outside zones "
                    f"(best overlap: {best_overlap*100:.1f}%)"
                )
        
        logger.info(f"ğŸ—ºï¸ Filtered: {len(filtered)}/{len(detections)} detections in zones")
        
        return filtered